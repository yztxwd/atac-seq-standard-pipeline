import pandas as pd
from snakemake.utils import validate, min_version

#### Set minimum snakemake version ####
min_version("5.1.2")

#### Load config and sample sheets ####

configfile: "config.yaml"
#validate(config, schema="schemas/config.schema.yaml")

samples = pd.read_table(config["samples"]).set_index(["sample", "rep", "unit"], drop=False)
#validate(samples, schema="schemas/samples.schema.yaml")

downloads = pd.read_table(config["downloads"]).set_index("fq", drop=False)

#### target rules ####
# target output names
conditions = list(samples['condition'].unique())

rule all:
    input:
        "output/qc/multiqc",
        expand("output/qc/bamPEFragmentSize/{samples}-{rep}.hist.png", zip, samples=samples["sample"], rep=samples["rep"]),
        expand("output/coverage/{samples}-{rep}.bamCov.bw", zip, samples=samples["sample"], rep=samples["rep"]),
        expand("output/genrich/{sample}-{rep}.{type}.genrich.narrowPeak", zip, 
                **(samples.reset_index(drop=True).groupby(["sample", "rep"]).
                    apply(lambda chunk: pd.Series({"type":"se" if pd.isnull(chunk["fq2"].iloc[0]) else "pe"})).
                    reset_index().
                    to_dict(orient='list')))
#        expand("output/idr/{samples}.idr.peaks", samples=samples.loc[samples["condition"]!="control", "sample"])

#### setup singularity ####

# this container defines the underlying OS for each job when using the workflow
# with --use-conda --use-singularity
singularity: "docker://continuumio/miniconda3"

#### setup report ####
report: "report/workflow.rst"

#### load rules ####